{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzK4kIeOpa74wT7SiUUWy9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prepare configuration for the pipeline and Google authorization, import libraries"],"metadata":{"id":"y8Xpwg10UJ8k"}},{"cell_type":"code","source":["# Import libraries\n","import os\n","import sys\n","from google.colab import auth\n","import yaml\n","# Mount your Google Drive to access persistent files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Authenticate user\n","auth.authenticate_user()\n","\n","# Create project direction\n","project_dir = \"/content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\"\n","os.makedirs(project_dir, exist_ok=True)\n","# Make sure the path is in sys.path\n","sys.path.append(project_dir)\n","\n","# Build .yaml-file\n","# Define the configuration data (this can be modified as per your need)\n","# Documentation for Open-Meteo requests\n","# https://pypi.org/project/openmeteo-requests/\n","\n","config_data = {\n","    \"project\": {\n","        \"project_id\": \"elt-siegburg-weather-forecast\",\n","        \"dataset_historical\": \"elt_weather_dataset_historical_siegburg_2017_2024\",\n","        \"table_historical\": \"elt_weather_table_historical_siegburg_2017\",\n","        \"dataset_month\": \"elt_weather_dataset_siegburg_october_2025\",\n","        \"table_8h\": \"elt_weather_8h_table_{timestamp}\",\n","        \"dataset_prediction\": \"elt_weather_dataset_prediction_siegburg_october_2025\",\n","    },\n","    # Weather data provided by Open-Meteo (CC BY 4.0)\n","    \"api_current\": {\n","        \"elt_weather_table_current\": \"https://api.open-meteo.com/v1/forecast?latitude=50.79086&longitude=7.2064056&current=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","    },\n","    # Weather data provided by Open-Meteo (CC BY 4.0)\n","      \"api_historical\":{\n","         \"elt_weather_table_historical_siegburg_2017\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2017-01-01&end_date=2017-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2018\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2018-01-01&end_date=2018-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2019\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2019-01-01&end_date=2019-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2020\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2020-01-01&end_date=2020-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2021\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2021-01-01&end_date=2021-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2022\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2022-01-01&end_date=2022-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2023\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2023-01-01&end_date=2023-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","         \"elt_weather_table_historical_siegburg_2024\": \"https://archive-api.open-meteo.com/v1/archive?latitude=50.79086&longitude=7.2064056&start_date=2024-01-01&end_date=2024-12-31&hourly=temperature_2m,relative_humidity_2m,surface_pressure,wind_speed_10m,wind_direction_10m,precipitation&timezone=Europe%2FBerlin\",\n","    },\n","    # Placeholders for open-meteo python packages\n","    \"params_current\": {\n","        \"latitude\": 50.79086,\n","        \"longitude\": 7.2064056,\n","        \"start_date\": \"2017-01-01\",\n","        \"end_date\": \"2017-12-31\",\n","        \"current\": [\"temperature_2m\", \"relative_humidity_2m\", \"windspeed_10m\", \"winddirection_10m\",\n","                    \"precipitation\", \"surface_pressure\"],\n","        \"timezone\": \"Europe/Berlin\"\n","    },\n","    # Placeholders for open-meteo python packages\n","    \"params_historical\": {\n","        \"latitude\": 50.79086,\n","        \"longitude\": 7.2064056,\n","        \"start_date\": \"2017-01-01\",\n","        \"end_date\": \"2017-12-31\",\n","        \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"wind_speed_10m\", \"wind_direction_10m\"],\n","        \"timezone\": \"Europe/Berlin\",\n","    }\n","}\n","\n","# Write this configuration to a YAML file in Colab\n","config_file_path = '/content/drive/MyDrive/elt_pipeline_weather_forecast/config.yaml'\n","with open(config_file_path, 'w') as file:\n","    yaml.dump(config_data, file, default_flow_style=False)\n","\n","# Confirm the file has been created\n","print(f\"config.yaml has been written to {config_file_path}\")"],"metadata":{"id":"eEbJ5m1cTbJB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762164650278,"user_tz":-60,"elapsed":1259,"user":{"displayName":"Mark","userId":"15317321788579729247"}},"outputId":"b8c35e71-302b-429a-c422-e3c1ccae0f71"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","config.yaml has been written to /content/drive/MyDrive/elt_pipeline_weather_forecast/config.yaml\n"]}]},{"cell_type":"markdown","source":["# GCP Ressource Management (gcp_utils/ or gcloud_admin/)"],"metadata":{"id":"84Slm0uR-nJ4"}},{"cell_type":"code","source":["# Import libraries\n","import os\n","import sys\n","from google.colab import auth\n","import datetime\n","\n","# Create gcp utilization direction\n","gcp_utils_dir = \"/content/drive/MyDrive/elt_pipeline_weather_forecast/gcp_utils\"\n","os.makedirs(gcp_utils_dir, exist_ok=True)\n","# Make sure the path is in sys.path\n","sys.path.append(gcp_utils_dir)\n","\n","# Assuming you have the table name template from your config\n","table_name_template = \"elt_weather_8h_table_{timestamp}\"\n","table_name_template_prediction = \"elt_weather_prediction_table_{timestamp}\"\n","\n","# Get the current timestamp\n","current_time = datetime.datetime.now()\n","\n","# Format the timestamp as yyyy-mm-ddThh:mm\n","# Note: BigQuery table names cannot contain hyphens or colons directly.\n","# You need to format it to be BigQuery-compatible, typically using underscores or removing special characters.\n","# A common format for BigQuery table names derived from timestamps is YYYYMMDD_HHMMSS or YYYY_MM_DD_HH_MM_SS.\n","# If you specifically need yyyy-mm-ddThh:mm for a different purpose (like a column value),\n","# you can use the format code below.\n","# For a BigQuery table name, use a compatible format like YYYYMMDD_HHMM.\n","\n","timestamp_bq_compatible = current_time.strftime(\"%Y%m%d_%H%M\")\n","print(f\"BigQuery compatible timestamp format: {timestamp_bq_compatible}\")\n","\n","# If you still want the yyyy-mm-ddThh:mm format for other uses:\n","timestamp_readable = current_time.strftime(\"%Y-%m-%dT%H:%M\")\n","print(f\"Readable timestamp format: {timestamp_readable}\")\n","\n","# Construct the BigQuery table name using the compatible format\n","table_id_8h_current = table_name_template.format(timestamp=timestamp_bq_compatible)\n","print(f\"Constructed BigQuery Table ID: {table_id_8h_current}\")\n","table_id_8h_prediction_current = table_name_template_prediction.format(timestamp=timestamp_bq_compatible)\n","print(f\"Constructed BigQuery Table ID: {table_id_8h_prediction_current}\")\n","\n","# This 'table_id' is what you would use when calling the BigQuery load function.\n","# For example:\n","# table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n","# job = client.load_table_from_dataframe(df, table_ref)\n","\n","# Generate .py files\n","# Load the YAML configuration file\n","load_config = \"\"\"\n","import yaml\n","\n","def load_config(config_file):\n","    with open(config_file, 'r') as file:\n","        return yaml.safe_load(file)\n","\"\"\"\n","# Save to file\n","with open(f\"{project_dir}/load_config.py\", \"w\") as f:\n","    f.write(load_config)\n","\n","# create_dataset.py - generate and save inside /contentdrive/MyDrive/elt_pipeline_weather_forecast/gcp_utils\n","extract_code = \"\"\"\n","from google.cloud import bigquery\n","\n","def create_dataset(PROJECT_ID, dataset_id, location=\"EU\"):\n","    # Creates a BigQuery dataset if it doesn't exist.\n","    client = bigquery.Client(project=PROJECT_ID)\n","    dataset_ref = client.dataset(dataset_id)\n","    try:\n","        client.get_dataset(dataset_ref)\n","        print(f\"Dataset '{dataset_id}' already exists.\")\n","    except:\n","        dataset = bigquery.Dataset(dataset_ref)\n","        dataset.location = location\n","        client.create_dataset(dataset)\n","        print(f\"Dataset '{dataset_id}' created.\")\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{gcp_utils_dir}/create_dataset.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# create_table.py - generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/gcp_utils\n","extract_code = \"\"\"\n","from google.cloud import bigquery\n","\n","def create_table(PROJECT_ID, dataset_id, table_id):\n","\n","    # Creates a BigQuery table if it doesn't exist.\n","    client = bigquery.Client(project=PROJECT_ID)\n","    dataset_ref = client.dataset(dataset_id)\n","    table_ref = dataset_ref.table(table_id)\n","    try:\n","        client.get_table(table_ref)\n","        print(f\"Table '{table_id}' already exists.\")\n","    except:\n","        # table = bigquery.Table(table_ref, schema=schema)\n","        table = bigquery.Table(table_ref)\n","        client.create_table(table)\n","        print(f\"Table '{table_id}' created.\")\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{gcp_utils_dir}/create_table.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# gcp_utils/main.py - generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/gcp_utils\n","extract_code = \"\"\"\n","from create_dataset import create_dataset\n","from create_table import create_table\n","from load_config import load_config\n","\n","def main(project, dataset, table):\n","\n","    # Load the config from the file we just created\n","    config = load_config('/content/drive/MyDrive/elt_pipeline_weather_forecast/config.yaml')\n","\n","    # Access the configurations\n","    project_id = config['project']['project_id']\n","    dataset_historical = config['project']['dataset_historical']\n","    table_historical = config['project']['table_historical']\n","    dataset_month = config['project']['dataset_month']\n","    table_8h = config['project']['table_8h']\n","    dataset_prediction = config['project']['dataset_prediction']\n","    params_current = config['params_current']\n","    params_historical = config['params_historical']\n","    url_historical_2017_2014 = config['api_historical']\n","    url_historical_2017 = config['api_historical']['elt_weather_table_historical_siegburg_2017']\n","    url_current = config['api_current']['elt_weather_table_current']\n","\n","    create_dataset(project, dataset)\n","    create_table(project, dataset, table)\n","\n","if __name__ == \"__main__\":\n","    # You can provide default values here, or leave it empty\n","    main(\"etl-weather-467607\", \"dataset\", \"table\")\n","\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{gcp_utils_dir}/manage_gcp.py\", \"w\") as f:\n","    f.write(extract_code)"],"metadata":{"id":"8Wpm5VPN-mlm","executionInfo":{"status":"ok","timestamp":1762164650300,"user_tz":-60,"elapsed":13,"user":{"displayName":"Mark","userId":"15317321788579729247"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"46337d96-8695-4f8f-ed09-ef7078d1a731"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["BigQuery compatible timestamp format: 20251103_1010\n","Readable timestamp format: 2025-11-03T10:10\n","Constructed BigQuery Table ID: elt_weather_8h_table_20251103_1010\n","Constructed BigQuery Table ID: elt_weather_prediction_table_20251103_1010\n"]}]},{"cell_type":"markdown","source":["# ELT/ML Pipeline (weather_pipeline/)"],"metadata":{"id":"N7u7MbzM-SVy"}},{"cell_type":"code","source":["# Generate .py files\n","# Load the YAML configuration file\n","load_config = \"\"\"\n","import yaml\n","\n","def load_config(config_file):\n","    with open(config_file, 'r') as file:\n","        return yaml.safe_load(file)\n","\"\"\"\n","# Save to file\n","with open(f\"{project_dir}/load_config.py\", \"w\") as f:\n","    f.write(load_config)\n","\n","# fetch.py fetches API weather data from https://open-meteo.com/ throgh URL\n","fetch_code = \"\"\"\n","import requests\n","import pandas as pd\n","from load_config import load_config\n","\n","def api_fetch(url, params=None):\n","    # Fetch API data with optional query parameters.\n","    response = requests.get(url, params=params)\n","    response.raise_for_status()\n","    return response.json()\n","\n","\n","def api_fetch_url(url, params=None):\n","\n","    response = requests.get(url, params=params)\n","    response.raise_for_status()\n","    api_data = response.json()\n","\n","    return api_data\n","\n","def fetch_historical_weather():\n","\n","    # Fetch historical weather data for all years defined in config.yaml.\n","    config = load_config('/content/drive/MyDrive/elt_pipeline_weather_forecast/config.yaml')\n","\n","    historical_data_dict = {}  # store raw JSON responses per year\n","    historical_df_dict = {}    # store converted DataFrames per year\n","\n","    # Loop through all URLs in config['api_historical']\n","    for key, url in config[\"api_historical\"].items():\n","        year = key.split(\"_\")[-1]  # extract year, e.g. \"2017\"\n","        print(f\"Fetching weather data for {year}...\")\n","\n","        # Fetch from API\n","        data = api_fetch_url(url)\n","        historical_data_dict[year] = data\n","\n","        # Convert the hourly data part to a DataFrame\n","        hourly_data = data.get(\"hourly\")\n","        if hourly_data:\n","            df = pd.DataFrame(hourly_data)\n","            df[\"year\"] = int(year)\n","            historical_df_dict[year] = df\n","            print(f\"  ‚Üí Loaded {len(df)} hourly records for {year}\")\n","\n","    return historical_data_dict, historical_df_dict\n","\"\"\"\n","# Save to file\n","with open(f\"{project_dir}/fetch_utils.py\", \"w\") as f:\n","    f.write(fetch_code)\n","\n","# load.py ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","extract_code = \"\"\"\n","import time\n","import pandas as pd\n","import numpy as np\n","import datetime\n","from google.cloud import bigquery\n","\n","def load_to_bigquery_raw(data, project_id, dataset, table):\n","    client = bigquery.Client(project=project_id)\n","    table_ref = f\"{project_id}.{dataset}.{table}\"\n","\n","    try:\n","        # Check if table exists\n","        table_obj = client.get_table(table_ref)\n","\n","        # Query row count\n","        row_count = table_obj.num_rows\n","        if row_count > 0:\n","            print(f\"Table {table_ref} already has data ({row_count} rows). Skipping load.\")\n","            return\n","        else:\n","            print(f\"Table {table_ref} exists but is empty. Loading data...\")\n","    except Exception as e:\n","        # Table doesn't exist\n","        print(f\"Table {table_ref} does not exist. It will be created and data will be loaded.\")\n","\n","    # Load data\n","    job = client.load_table_from_dataframe(data, table_ref)\n","    job.result()\n","    print(f\"Loaded {job.output_rows} rows to {table_ref}\")\n","\n","def load_to_bigquery(data, project_id, dataset, table):\n","    client = bigquery.Client(project=project_id)\n","    table_ref = f\"{project_id}.{dataset}.{table}\"\n","\n","    try:\n","        # Check if table exists\n","        table_obj = client.get_table(table_ref)\n","\n","        # Query row count\n","        row_count = table_obj.num_rows\n","        if row_count > 0:\n","            print(f\"Table {table_ref} already has data ({row_count} rows). Skipping load.\")\n","            return\n","        else:\n","            print(f\"Table {table_ref} exists but is empty. Loading data...\")\n","    except Exception as e:\n","        # Table doesn't exist\n","        print(f\"Table {table_ref} does not exist. It will be created and data will be loaded.\")\n","\n","    # Load data\n","    job = client.load_table_from_dataframe(data, table_ref)\n","    job.result()\n","    print(f\"Loaded {job.output_rows} rows to {table_ref}\")\n","\n","# Function to convert NumPy array to DataFrame\n","def numpy_to_dataframe(np_array):\n","    # If np_array is a single value (scalar), reshape it into a DataFrame\n","    if np_array.ndim == 1:  # For a 1D array\n","        return pd.DataFrame(np_array, columns=[\"prediction\"])\n","    elif np_array.ndim == 2:  # For a 2D array\n","        return pd.DataFrame(np_array, columns=[\"prediction\"])\n","    else:\n","        raise ValueError(\"Only 1D or 2D NumPy arrays are supported.\")\n","\n","# Function to fetch current month's number\n","def current_month():\n","    current_date = datetime.datetime.now()\n","    return current_date.month\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/load_utils.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# extract.py ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","extract_code = \"\"\"\n","import pandas as pd\n","from google.cloud import bigquery\n","\n","def extract_weather_historical(project_id, dataset_historical, table_historical):\n","    '''Default full extract.'''\n","    client = bigquery.Client(project=project_id)\n","    table_ref = f\"{project_id}.{dataset_historical}.{table_historical}\"\n","    query = f\"SELECT * FROM `{table_ref}`\"\n","    df = client.query(query).to_dataframe()\n","    return df\n","\n","def extract_weather_current(project_id, dataset_current, table_current):\n","    '''Default full extract.'''\n","    client = bigquery.Client(project=project_id)\n","    table_ref = f\"{project_id}.{dataset_current}.{table_current}\"\n","    query = f\"SELECT * FROM `{table_ref}`\"\n","    df = client.query(query).to_dataframe()\n","    return df\n","\n","def extract_full_query(query, project_id):\n","    client = bigquery.Client(project=project_id)\n","    try:\n","        df = client.query(query).to_dataframe()\n","        print(f\"Query executed successfully. Retrieved {len(df)} rows.\")\n","        return df\n","    except Exception as e:\n","        print(f\"Error executing query: {e}\")\n","        return pd.DataFrame()\n","\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/query_utils.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# transform.py ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","extract_code = \"\"\"\n","import pandas as pd\n","from google.cloud import bigquery\n","\n","def transform_data(df):\n","    df['date'] = pd.to_datetime(df['time']).dt.date\n","    df = df.rename(columns={\n","        \"temperature_2m\": \"temp\",\n","        \"relative_humidity_2m\": \"rel_humidity\",\n","        \"surface_pressure\": \"pressure\",\n","        \"wind_speed_10m\": \"wind_speed\",\n","        \"wind_direction_10m\": \"wind_direction\",\n","        \"precipitation\": \"precip\",\n","    })\n","    df = df.dropna(subset=['temp', 'rel_humidity', 'pressure',\n","                          'wind_speed', 'wind_direction', 'precip'])\n","    return df[['date', 'temp', 'rel_humidity', 'pressure',\n","                          'wind_speed', 'wind_direction', 'precip']]\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/transform_utils.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# predict.py ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","extract_code = \"\"\"\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, r2_score\n","\n","def train_model(df_trans_historical):\n","\n","    # Train a Random Forest model on historical weather data.\n","    # Returns trained model\n","\n","    features = ['rel_humidity', 'precip', 'pressure', 'wind_speed', 'wind_direction']\n","    target = 'temp'\n","\n","    df = df_trans_historical.sort_values(\"date\")\n","    X_train = df[features]\n","    y_train = df[target]\n","\n","    model = RandomForestRegressor(n_estimators=100, random_state=42)\n","    model.fit(X_train, y_train)\n","    return model\n","\n","def predict_current(model, df_trans_current):\n","\n","    # Use trained model to predict current temperature from a single or few records.\n","    # Returns:\n","    # - prediction(s)\n","\n","    features = ['rel_humidity', 'precip', 'pressure', 'wind_speed', 'wind_direction']\n","\n","    # Make sure input is DataFrame with expected columns\n","    if isinstance(df_trans_current, pd.Series):\n","        df_trans_current = df_trans_current.to_frame().T\n","\n","    prediction = model.predict(df_trans_current[features])\n","    return prediction\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/predictor_utils.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# visualize.py ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","extract_code = \"\"\"\n","import matplotlib.pyplot as plt\n","\n","def visualize_current_prediction(df_trans_current, pred_temp):\n","\n","    # Display current input features and predicted temperature.\n","    current = df_trans_current.iloc[0]  # Assuming 1 row\n","    print(\"Current weather input:\")\n","    display(current.to_frame(name=\"value\"))\n","    print(f\"Predicted temperature: {pred_temp[0]:.2f} ¬∞C\")\n","\n","    # Plot weather features + predicted temp\n","    feature_values = current[['rel_humidity', 'precip', 'pressure', 'wind_speed', 'wind_direction']]\n","\n","    plt.figure(figsize=(10, 5))\n","    bars = plt.bar(feature_values.index, feature_values.values, color='skyblue')\n","    plt.title(\"Current Weather Features\")\n","    plt.ylabel(\"Value\")\n","    plt.xticks(rotation=45)\n","    plt.grid(axis='y')\n","    plt.tight_layout()\n","    plt.figtext(0.99, 0.01, 'Weather data provided by Open-Meteo.com (CC BY 4.0)', ha='right', va='bottom', fontsize=8, color='gray')\n","    plt.show()\n","\n","    # Show predicted temperature as a separate bar\n","    plt.figure(figsize=(4, 5))\n","    plt.bar(['Predicted Temp'], [pred_temp[0]], color='salmon')\n","    plt.ylim(0, max(50, pred_temp[0] + 5))  # Adjust Y-axis\n","    plt.title(\"Predicted Temperature\")\n","    plt.ylabel(\"¬∞C\")\n","    plt.grid(axis='y')\n","    plt.tight_layout()\n","    plt.show()\n","\n","def plot_predictions_over_time(dates, actual, predicted):\n","\n","    # Plot predicted vs actual temperature over time.\n","    plt.figure(figsize=(12,6))\n","    plt.plot(dates, actual, label='Actual Temperature', linewidth=2)\n","    plt.plot(dates, predicted, label='Predicted Temperature', linestyle='--')\n","    plt.title(\"Predicted vs Actual Temperature\")\n","    plt.xlabel(\"Date\")\n","    plt.ylabel(\"Temperature (¬∞C)\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.figtext(0.99, 0.01, 'Weather data provided by Open-Meteo.com (CC BY 4.0)', ha='right', va='bottom', fontsize=8, color='gray')\n","    plt.show()\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/visualization_utils.py\", \"w\") as f:\n","    f.write(extract_code)\n","\n","\n","# main.py ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","main_code = \"\"\"\n","import yaml\n","import json\n","import pandas as pd\n","import numpy as np\n","import datetime\n","from load_config import load_config\n","from fetch_utils import api_fetch, api_fetch_url, fetch_historical_weather\n","from query_utils import extract_weather_current, extract_full_query\n","from load_utils import load_to_bigquery_raw, load_to_bigquery, numpy_to_dataframe, current_month\n","from transform_utils import transform_data\n","from predictor_utils import train_model, predict_current\n","from sklearn.metrics import mean_absolute_error\n","from transform_utils import transform_data\n","from visualization_utils import visualize_current_prediction, plot_predictions_over_time\n","\n","\n","def main(project_id, dataset_historical, table_historical, dataset_month, table_id_8h_current, table_id_8h_prediction_current, dataset_prediction):\n","    print(\">>> main() is running.\")\n","\n","    # Load the config from the .yaml file\n","    config = load_config('/content/drive/MyDrive/elt_pipeline_weather_forecast/config.yaml')\n","\n","    # Access the configurations\n","    project_id = config['project']['project_id']\n","    dataset_historical = config['project']['dataset_historical']\n","    table_historical = config['project']['table_historical']\n","    dataset_month = config['project']['dataset_month']\n","    table_8h = config['project']['table_8h']\n","    dataset_prediction = config['project']['dataset_prediction']\n","    params_current = config['params_current']\n","    params_historical = config['params_historical']\n","    url_historical_2017_2014 = config['api_historical']\n","    url_historical_2017 = config['api_historical']['elt_weather_table_historical_siegburg_2017']\n","    url_current = config['api_current']['elt_weather_table_current']\n","\n","    # Print values to confirm\n","    print(f\"Project ID: {project_id}\")\n","    print(f\"Dataset Historical: {dataset_historical}\")\n","    print(f\"Table Historical: {table_historical}\")\n","    print(f\"Dataset Month: {dataset_month}\")\n","    print(f\"Table Current: {table_id_8h_current}\")\n","\n","    # Fetching data from the API\n","    print(\">>> Starting main API fetch\")\n","    # Fetch historical data from the weather API\n","    weather_data_historical = api_fetch_url(url_historical_2017)\n","\n","    # Fetch historical data from the weather API for each year 2017-2024\n","    historical_data_dict, historical_df_dict = fetch_historical_weather()\n","\n","    # Example: access one year‚Äôs (2017) data\n","    weather_data_historical_2017 = historical_data_dict.get(\"2017\")\n","\n","    print(\"Received data for the year 2017:\")\n","    print(f\"Type: {type(weather_data_historical_2017)}\")\n","\n","    if weather_data_historical_2017:\n","        print(\"Top-level keys:\", list(weather_data_historical_2017.keys()))\n","        hourly_data = weather_data_historical_2017.get(\"hourly\")\n","        if hourly_data:\n","            print(\"Hourly keys:\", list(hourly_data.keys())[:10])\n","            print(\"First 3 time entries:\", hourly_data.get(\"time\", [])[:3])\n","    else:\n","        print(\"No data found for 2017.\")\n","\n","    # Fetch current data from the weather API\n","    weather_data_current = api_fetch_url(url_current)\n","    print(\"API fetch for current data:\",weather_data_current)\n","    print(\"Keys in weather_data_current:\", weather_data_current.keys())\n","    print(\"Type of weather_data_current:\", type(weather_data_current))\n","\n","    # Access the nested current data for current data\n","    df_current = pd.DataFrame([weather_data_current['current']])\n","    print(\"Current data:\")\n","    print(df_current.head())\n","\n","    print(\">>> API fetch ends\")\n","\n","    print(\">>> Loading fetched historical data to BigQuery\")\n","\n","    # Load fetched historical data to BigQuery\n","    for year, df in historical_df_dict.items():\n","        if df.empty:\n","            print(f\"No data for year {year}, skipping.\")\n","            continue\n","        table_name = f\"elt_weather_table_historical_siegburg_{year}\"\n","        print(f\"Loading data for year {year} into {table_name}...\")\n","\n","        load_to_bigquery_raw(df, project_id, dataset_historical, table_name)\n","\n","    # Load fetched current data to BigQuery\n","    print(\">>> Loading fetched current data to BigQuery\")\n","    load_to_bigquery_raw(df_current, project_id, dataset_month, table_id_8h_current)\n","    print(\">>> Loading ends\")\n","\n","    # # Get the current month (for future seasonal predictions)\n","    # month_input = current_month()\n","    # print(f\"Current month: {month_input}\")\n","\n","    # # Extract historical weather data from BigQuery and format to DataFrame (for future seasonal predictions)\n","    # print(f\">>> Extracting historical data from BigQuery for the month {month_input}\")\n","\n","    # Load historical data from BigQuery for the current month\n","    # month_input = 1  # Example: January (for future seasonal predictions)\n","\n","    # -------------------------------------------------------------------------\n","    # Automatically determine the \"seasonal window\" of months to include in the\n","    # historical dataset based on the current month. This allows the model to\n","    # only use data from months that are relevant to the time of year being\n","    # predicted (e.g., if we are predicting in October, we include September,\n","    # October, and November data from past years).\n","    #\n","    # Steps:\n","    # 1. Get the current date and time using datetime.now().\n","    # 2. Extract the current month (1-12) from the current date.\n","    # 3. Define a seasonal window as ¬±1 month around the current month.\n","    #    - Use modulo arithmetic to correctly wrap around the year (e.g., if\n","    #      current month is January, the window includes December of previous\n","    #      year, January, and February).\n","    # 4. This 'season_months' list is later used to filter the historical data\n","    #    so that only rows where df['month'] is in this list are included.\n","    # -------------------------------------------------------------------------\n","\n","    # Automatically get the current month\n","    current_time = datetime.datetime.now()\n","    target_month = current_time.month\n","    print(f\"Detected current month: {target_month}\")\n","\n","    # Define a ¬±1 month seasonal window\n","    season_months = [(target_month - 1) % 12 or 12,\n","                    target_month,\n","                    (target_month + 1 - 1) % 12 + 1]\n","    print(f\"Using seasonal months: {season_months}\")\n","\n","    df_historical = []\n","\n","    for year in range(2017, 2025):\n","        table = f\"elt_weather_table_historical_siegburg_{year}\"\n","\n","        query = f'''\n","        SELECT\n","          time,\n","          temperature_2m AS temp,\n","          relative_humidity_2m AS rel_humidity,\n","          surface_pressure AS pressure,\n","          wind_speed_10m AS wind_speed,\n","          wind_direction_10m AS wind_direction,\n","          precipitation AS precip,\n","\n","          -- Temperature lags\n","          LAG(temperature_2m, 1) OVER (ORDER BY time) AS lag_temp_1h,\n","          LAG(temperature_2m, 2) OVER (ORDER BY time) AS lag_temp_2h,\n","          LAG(temperature_2m, 3) OVER (ORDER BY time) AS lag_temp_3h,\n","\n","          -- Humidity lags\n","          LAG(relative_humidity_2m, 1) OVER (ORDER BY time) AS lag_rel_humidity_1h,\n","          LAG(relative_humidity_2m, 2) OVER (ORDER BY time) AS lag_rel_humidity_2h,\n","          LAG(relative_humidity_2m, 3) OVER (ORDER BY time) AS lag_rel_humidity_3h,\n","\n","          -- Pressure lags\n","          LAG(surface_pressure, 1) OVER (ORDER BY time) AS lag_pressure_1h,\n","          LAG(surface_pressure, 2) OVER (ORDER BY time) AS lag_pressure_2h,\n","          LAG(surface_pressure, 3) OVER (ORDER BY time) AS lag_pressure_3h,\n","\n","          -- Wind speed lags\n","          LAG(wind_speed_10m, 1) OVER (ORDER BY time) AS lag_wind_speed_1h,\n","          LAG(wind_speed_10m, 2) OVER (ORDER BY time) AS lag_wind_speed_2h,\n","          LAG(wind_speed_10m, 3) OVER (ORDER BY time) AS lag_wind_speed_3h,\n","\n","          -- Wind direction lags\n","          LAG(wind_direction_10m, 1) OVER (ORDER BY time) AS lag_wind_direction_1h,\n","          LAG(wind_direction_10m, 2) OVER (ORDER BY time) AS lag_wind_direction_2h,\n","          LAG(wind_direction_10m, 3) OVER (ORDER BY time) AS lag_wind_direction_3h,\n","\n","          -- Precipitation lags\n","          LAG(precipitation, 1) OVER (ORDER BY time) AS lag_precip_1h,\n","          LAG(precipitation, 2) OVER (ORDER BY time) AS lag_precip_2h,\n","          LAG(precipitation, 3) OVER (ORDER BY time) AS lag_precip_3h\n","\n","        FROM `{project_id}.{dataset_historical}.{table}`\n","        '''\n","\n","        df = extract_full_query(query, project_id)\n","\n","        if not df.empty:\n","            df['time'] = pd.to_datetime(df['time'])\n","            df['month'] = df['time'].dt.month\n","\n","            # Filter data to ¬±1 month around current time\n","            df = df[df['month'].isin(season_months)]\n","\n","            # Add wind direction cyclical encoding\n","            df['wind_dir_sin'] = np.sin(np.deg2rad(df['wind_direction']))\n","            df['wind_dir_cos'] = np.cos(np.deg2rad(df['wind_direction']))\n","\n","            # Add diurnal cyclical encodings\n","            df['hour'] = df['time'].dt.hour\n","            df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n","            df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n","\n","            # Drop rows with missing lag values\n","            df.dropna(inplace=True)\n","\n","            df_historical.append(df)\n","            print(f\"Loaded {len(df)} rows from {table}\")\n","        else:\n","            print(f\"No data found for year {year}.\")\n","\n","    # === Combine and summarize ===\n","    if df_historical:\n","        df_historical = pd.concat(df_historical, ignore_index=True)\n","        print(f\"Total rows after seasonal concatenation: {len(df_historical)}\")\n","\n","        # Optional rolling/aggregate features\n","        df_historical['temp_mean_last3h'] = df_historical[['lag_temp_1h','lag_temp_2h','lag_temp_3h']].mean(axis=1)\n","        df_historical['wind_speed_mean_last3h'] = df_historical[['lag_wind_speed_1h','lag_wind_speed_2h','lag_wind_speed_3h']].mean(axis=1)\n","        df_historical['humidity_mean_last3h'] = df_historical[['lag_rel_humidity_1h','lag_rel_humidity_2h','lag_rel_humidity_3h']].mean(axis=1)\n","\n","        print(df_historical.head())\n","    else:\n","        print(\"No seasonal historical data loaded.\")\n","\n","\n","    # Extract current weather data from BigQuery and format into DataFrame\n","    print(\">>> Extracting current data from BigQuery\")\n","    # Extract current weather data from BigQuery and format into DataFrame\n","    df_current = extract_weather_current(project_id, dataset_month, table_id_8h_current)\n","    print(\"Current data from BigQuery:\")\n","    print(df_current.head())\n","    print(\">>> Extracting ends\")\n","\n","    # Transform historical weather data\n","    print(\">>> Transforming historical data\")\n","    df_trans_historical = transform_data(df_historical)\n","    print(df_trans_historical.head())\n","\n","    # Transform current weather data\n","    print(\">>> Transforming current data\")\n","    df_trans_current = transform_data(df_current)\n","    print(df_trans_current.head())\n","    print(\">>> Transforming ends\")\n","\n","    print(\">>> Machine Learning prediction and visualization starts\")\n","    # Train ML model and make predictions\n","    # df_trans_historical ‚Üí large set\n","    # df_trans_current ‚Üí 1 row from current API\n","\n","    # Train model on past data\n","    model = train_model(df_trans_historical)\n","    # Predict temp from current values\n","    pred_temp = predict_current(model, df_trans_current)\n","    print(f\"‚Üí Predicted current temperature: {pred_temp[0]:.2f} ¬∞C\")\n","\n","    X_test = df_trans_historical[['rel_humidity', 'precip', 'pressure', 'wind_speed', 'wind_direction']]\n","    y_test = df_trans_historical['temp']\n","    y_pred = model.predict(X_test)\n","    plot_predictions_over_time(df_trans_historical['date'], y_test, y_pred)\n","\n","    # Show prediction nicely\n","    visualize_current_prediction(df_trans_current, pred_temp)\n","\n","    print(\">>> Machine Learning prediction and visualization end\")\n","\n","    # Load prediction to BigQuery\n","    print(\">>> Loading prediction to BigQuery\")\n","\n","    df_pred = numpy_to_dataframe(pred_temp)\n","    load_to_bigquery(df_pred, project_id, dataset_prediction, table_id_8h_prediction_current)\n","\n","    print(\">>> Loading ends\")\n","\n","    print(\">>> main() is done.\")\n","\n","if __name__ == \"__main__\":\n","    # You can provide default values here, or leave it empty\n","    pass # This will not run when imported\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/main.py\", \"w\") as f:\n","    f.write(main_code)\n","\n","\n","# dockerfile ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","dockerfile_code = \"\"\"\n","FROM python:3.10-slim\n","\n","WORKDIR /app\n","\n","COPY . .\n","\n","RUN pip install --no-cache-dir -r requirements.txt\n","\n","CMD [\"python\", \"main.py\"]\n","\"\"\"\n","\n","# Save to file\n","with open(f\"{project_dir}/Dockerfile\", \"w\") as f:\n","    f.write(dockerfile_code)\n"],"metadata":{"id":"2fXilluBmsqd","executionInfo":{"status":"ok","timestamp":1762164650404,"user_tz":-60,"elapsed":86,"user":{"displayName":"Mark","userId":"15317321788579729247"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHfeqU71shg8","executionInfo":{"status":"ok","timestamp":1762164651441,"user_tz":-60,"elapsed":1026,"user":{"displayName":"Mark","userId":"15317321788579729247"}},"outputId":"f91fbf5d-2458-4229-b177-68f9c46608a0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Requirements / README / License"],"metadata":{"id":"ki058GSQEejS"}},{"cell_type":"code","source":["# requirements.txt ‚Äî generate and save inside /content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\n","requirements_code = '''\n","google-colab\n","PyYAML\n","google-cloud-bigquery\n","requests\n","requests_cache\n","retry-requests\n","pandas\n","scikit-learn\n","matplotlib\n","'''\n","\n","with open(f\"/content/drive/MyDrive/elt_pipeline_weather_forecast/requirements.txt\", \"w\") as f:\n","    f.write(requirements_code)\n","\n","\n","readme_code = \"\"\"\n","# üå¶Ô∏è Weather Forecasting ELT Pipeline\n","\n","This project implements a **modular, scalable end-to-end ELT (Extract, Load, Transform)** pipeline for **weather forecasting** using **Google Colab Python** and **Google Cloud Platform (BigQuery)**. It automates the process of collecting, storing, transforming, and modeling weather data to predict **hourly temperatures** in **Siegburg, Germany**.\n","\n","The weather forecasting is at this stage in a simplified form to represent the function of the pipeline. In future, there may be a deeper focus on more complex machine learning models, but for now, it serves the purpose of understanding the pipeline.\n","Data is sourced from the **[Open-Meteo API](https://open-meteo.com/)** and processed into a structured format to support **machine learning-based forecasting**. The pipeline is built for experimentation and can be scaled with additional features like orchestration or containerization.\n","\n","---\n","\n","## Project Overview\n","\n","The pipeline performs the following high-level steps:\n","\n","1. **Extract** historical and current weather data via the [Open-Meteo API](https://open-meteo.com/).\n","2. **Load** this data into **Google BigQuery**, partitioned by year.\n","3. **Transform** and prepare the data through feature engineering.\n","4. **Predict** hourly temperatures using a **Random Forest** regression model.\n","5. **Store** the predictions back to BigQuery.\n","\n","---\n","\n","## Tools and Technologies Used\n","\n","- **Google Colab**: Interactive environment for development, experimentation, and running Python code.\n","- **Google Cloud Platform (GCP)**: Provides the cloud infrastructure for this project, including **BigQuery** for storing and querying large weather datasets.\n","\n","\n","This combination of tools ensures an efficient, scalable, and cloud-native approach to building the weather forecasting pipeline.\n","\n","For data retrieval, the project uses the **[Open-Meteo API](https://open-meteo.com/)**, which provides weather forecasts for different geographical regions.\n","\n","---\n","\n","## Attribution for Weather Data\n","\n","This project uses weather data provided by [Open-Meteo.com](https://open-meteo.com), which is offered under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.\n","\n","You are free to copy, redistribute, and adapt the data, but please ensure proper attribution:\n","\n","- **Credit**: \"Weather data by Open-Meteo.com\"\n","- **Link**: [Open-Meteo.com](https://open-meteo.com)\n","- **Changes**: If you make changes to the data, you must indicate that modifications were made.\n","\n","For more information, refer to the [Open-Meteo Terms of Service](https://open-meteo.com/en/terms).\n","\n","**Example attribution (HTML for display in web or applications):**\n","```html\n","<a href=\"https://open-meteo.com/\">\n","\tWeather data by Open-Meteo.com\n","</a>\n","```\n","---\n","\n","## Project Structure\n","\n","```text\n","weather-forecasting-elt/\n","‚îú‚îÄ‚îÄ elt_pipeline_weather.ipynb      # Main notebook runner\n","‚îú‚îÄ‚îÄ gcp_utils/                      # Utilities for Google Cloud (BigQuery)\n","‚îÇ   ‚îú‚îÄ‚îÄ create_dataset.py\n","‚îÇ   ‚îú‚îÄ‚îÄ create_table.py\n","‚îÇ   ‚îî‚îÄ‚îÄ manage_gcp.py\n","‚îú‚îÄ‚îÄ weather_pipeline/               # ELT and ML logic\n","‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile\n","‚îÇ   ‚îú‚îÄ‚îÄ fetch_utils.py\n","‚îÇ   ‚îú‚îÄ‚îÄ load.py\n","‚îÇ   ‚îú‚îÄ‚îÄ load_config.py\n","‚îÇ   ‚îú‚îÄ‚îÄ main.py\n","‚îÇ   ‚îú‚îÄ‚îÄ predictor_utils.py\n","‚îÇ   ‚îú‚îÄ‚îÄ query_utils.py\n","‚îÇ   ‚îú‚îÄ‚îÄ transform_utils.py\n","‚îÇ   ‚îú‚îÄ‚îÄ visualization_utils.py\n","‚îú‚îÄ‚îÄ config.yaml                     # Central configuration file\n","‚îú‚îÄ‚îÄ requirements.txt                # Required packages\n","‚îî‚îÄ‚îÄ README.md                       # This file\n","```\n","\n","---\n","\n","## ELT Process\n","\n","### 1. Extract\n","- Fetches historical weather data (2017‚Äì2024) and current conditions using Open-Meteo's REST API.\n","- Stores raw JSON responses in memory and converts them to structured Pandas DataFrames.\n","\n","### 2. Load\n","- Loads raw weather data into **Google BigQuery**, storing each year's data in a separate table.\n","- Data is loaded using the `google-cloud-bigquery` Python client.\n","\n","### 3. Transform\n","- Cleans and formats the raw data.\n","- Feature engineering includes:\n","  - `temperature`, `rel_humidity`, `precipitation`, `pressure`, `wind_speed`, `wind_direction`\n","- Combines historical data across multiple years (e.g., for October only).\n","- Prepares the data for machine learning.\n","\n","### 4. Model (Predict)\n","- Trains a **Random Forest Regressor** using historical October data.\n","- Predicts hourly temperatures.\n","- Evaluates and optionally visualizes prediction results.\n","\n","### 5. Store\n","- Saves prediction results back to BigQuery for analytics or dashboarding.\n","\n","---\n","\n","## Usage Guide\n","\n","### 1. Set your Google Cloud Project ID\n","- Before running the notebook, open `elt_pipeline_weather.ipynb` and locate the configuration dictionary.\n","- Replace the `project_id` value with your own Google Cloud project ID and `dataset_month` to the current month, for example:\n","\n","```python\n","config_data = {\n","    \"project\": {\n","        \"project_id\": \"your-gcp-project-id\",\n","        \"dataset_historical\": \"elt_weather_dataset_historical_siegburg_2017_2024\",\n","        \"table_historical\": \"elt_weather_table_historical_siegburg_2017\",\n","        \"dataset_month\": \"elt_weather_dataset_siegburg_october_2025\",\n","        \"table_8h\": \"elt_weather_8h_table_{timestamp}\",\n","        # ... other config values ...\n","    }\n","}\n","```\n","\n","### 2. Run the Notebook\n","#### Execute all cells sequentially. This will:\n","- Fetch historical and current weather data\n","- Load data into BigQuery\n","- Run transformations and train a Random Forest model\n","- Store prediction results back into BigQuery\n","\n","### 3. View Results\n","After completion, explore the predictions stored in your BigQuery dataset or extend the project with visualization tools.\n","\n","---\n","\n","\n","## Key Modules\n","\n","### `gcp_utils/`\n","- `create_dataset.py` ‚Äì Create BigQuery datasets\n","- `create_table.py` ‚Äì Create BigQuery tables\n","- `jobtables.py` ‚Äì Submit query jobs to BigQuery\n","- `manage_gcp.py` ‚Äì CLI runner for GCP utilities\n","\n","### `weather_pipeline/`\n","- `fetch_utils.py` ‚Äì Handle API requests and data formatting\n","- `load_utils.py` ‚Äì Load Pandas DataFrames to BigQuery, and convert NumPy arrays to DataFrames\n","- `load_config.py` ‚Äì Read config from YAML file\n","- `main.py` ‚Äì Central runner script for the pipeline\n","- `predictor_utils.py` ‚Äì Train and evaluate prediction models\n","- `query_utils.py` ‚Äì Construct and run SQL queries\n","- `transform_utils.py` ‚Äì Feature engineering and cleaning\n","- `visualization_utils.py` ‚Äì Plotting and metrics\n","\n","---\n","\n","## Configuration\n","\n","- `config.yaml`: Central configuration file for setting:\n","  - API parameters\n","  - BigQuery dataset/table names\n","  - ML model settings\n","\n","---\n","\n","## Requirements\n","\n","- Python 3.7+\n","- Google Cloud credentials (service account with BigQuery permissions)\n","- Jupyter Notebook or Google Colab\n","- Install dependencies via:\n","\n","```bash\n","pip install -r requirements.txt\n","```\n","\n","---\n","\n","## Future Work\n","\n","This project is actively being expanded to improve automation, portability, and predictive capabilities:\n","\n","### Orchestration\n","- Add workflow orchestration with **Airflow**\n","- Schedule regular data updates and monitor pipeline runs\n","\n","### Dockerization\n","- Containerize the pipeline using **Docker** for reproducible environments\n","- Facilitate deployment across different machines or cloud platforms\n","\n","### Machine Learning\n","- Integrate a lightweight ML component to generate **1-hour weather forecasts**\n","- Continuously retrain and evaluate the model as new data arrives\n","\n","**Goal:**\n","A reproducible, automated ELT pipeline that collects, transforms, and predicts short-term weather data with minimal manual intervention.\n","\n","---\n","\n","## License\n","\n","- This project is licensed under the [MIT License](LICENSE).\n","- See the LICENSE file for details.\n","\n","---\n","\n","## Acknowledgements\n","\n","- Thanks to public weather data providers Open Meteo for API access\n","- Inspired by best practices in ELT pipeline design and reproducible data science\n","\"\"\"\n","\n","with open(\"/content/drive/MyDrive/elt_pipeline_weather_forecast/README.md\", \"w\") as f:\n","    f.write(readme_code)\n","\n","# Python code to create the LICENSE file\n","# Python code to create the LICENSE file with the updated text\n","\n","license_text = \"\"\"\n","MIT License\n","\n","Copyright (c) 2025 claxcoding\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n","THE SOFTWARE.\n","\n","Acknowledgments\n","\n","This project utilizes the following platforms and services:\n","- Google Colab: For interactive development, coding, and experimentation.\n","- Google Cloud Platform (BigQuery): For data storage and processing.\n","- Open-Meteo API: For fetching weather data.\n","\n","\"\"\"\n","\n","# Create LICENSE file with updated text in Colab environment\n","with open(\"/content/drive/MyDrive/elt_pipeline_weather_forecast/LICENSE\", \"w\") as license_file:\n","    license_file.write(license_text)\n"],"metadata":{"id":"CUhx53ojEcwl","executionInfo":{"status":"ok","timestamp":1762164651461,"user_tz":-60,"elapsed":17,"user":{"displayName":"Mark","userId":"15317321788579729247"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Run Creation Dataset/Table Script"],"metadata":{"id":"BHlbs45vH542"}},{"cell_type":"code","source":["# Import libraries\n","import sys\n","import importlib\n","\n","# Define the directory path where the gcp_utils Python modules are located\n","gcp_utils_dir = \"/content/drive/MyDrive/elt_pipeline_weather_forecast/gcp_utils\"\n","project_dir = \"/content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\"\n","\n","# Add gcp_utils to the front of the search path to give it priority\n","if gcp_utils_dir not in sys.path:\n","    sys.path.insert(0, gcp_utils_dir)\n","    print(sys.path)\n","\n","# Add project_dir to the front of the search path to give it priority\n","if project_dir not in sys.path:\n","    sys.path.insert(0, project_dir)\n","    print(sys.path)\n","\n","import manage_gcp\n","from load_config import load_config\n","\n","# Reload the 'manage_gcp' module to reflect any recent changes made to its code.\n","# This is useful in environments like Jupyter/Colab where code may be edited and re-run dynamically.\n","importlib.reload(manage_gcp)\n","\n","\n","# Verify it's the correct path\n","print(manage_gcp.__file__)\n","\n","# Load the config from the file we just created\n","config = load_config('/content/drive/MyDrive/elt_pipeline_weather_forecast/config.yaml')\n","\n","# Access the configurations\n","project_id = config['project']['project_id']\n","dataset_historical = config['project']['dataset_historical']\n","table_historical = config['project']['table_historical']\n","dataset_month = config['project']['dataset_month']\n","table_8h = config['project']['table_8h']\n","dataset_prediction = config['project']['dataset_prediction']\n","params_current = config['params_current']\n","params_historical = config['params_historical']\n","url_historical_2017_2014 = config['api_historical']\n","url_historical_2017 = config['api_historical']['elt_weather_table_historical_siegburg_2017']\n","url_current = config['api_current']['elt_weather_table_current']\n","\n","# Loop through each table name in the list 'url_historical_2017_2014'\n","# and call the 'main' function from the 'manage_gcp' module.\n","# This creates tables for each historical weather table in the BigQuery dataset.\n","for n in url_historical_2017_2014:\n","  manage_gcp.main(project_id, dataset_historical, n)\n","\n","# Call the 'main' function from the 'manage_gcp' module and create a current table\n","# Assuming table_id_8h_current is defined elsewhere in the notebook\n","manage_gcp.main(project_id, dataset_month, table_id_8h_current)\n","\n","# Call the 'main' fnction from the 'manage_gcp' module and create prediction dataset and table\n","# Assuming table_id_8h_prediction_current is defined elsewhere in the notebook\n","manage_gcp.main(project_id, dataset_prediction, table_id_8h_prediction_current)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obgkVdFuH6TN","executionInfo":{"status":"ok","timestamp":1762164661257,"user_tz":-60,"elapsed":9778,"user":{"displayName":"Mark","userId":"15317321788579729247"}},"outputId":"678e40d3-c022-4c68-9dd7-b603ca415116"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/elt_pipeline_weather_forecast/gcp_utils/manage_gcp.py\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2017' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2018' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2019' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2020' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2021' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2022' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2023' already exists.\n","Dataset 'elt_weather_dataset_historical_siegburg_2017_2024' already exists.\n","Table 'elt_weather_table_historical_siegburg_2024' already exists.\n","Dataset 'elt_weather_dataset_siegburg_october_2025' already exists.\n","Table 'elt_weather_8h_table_20251103_1010' created.\n","Dataset 'elt_weather_dataset_prediction_siegburg_october_2025' already exists.\n","Table 'elt_weather_prediction_table_20251103_1010' created.\n"]}]},{"cell_type":"markdown","source":["# Run the Pipeline-Script"],"metadata":{"id":"9Su47eHc1jzn"}},{"cell_type":"code","source":["# Import librariesand call main() directly\n","import sys\n","import importlib\n","import main\n","main_project_dir = \"/content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline\"\n","\n","\n","# Add gcp_utils to the front of the search path to give it priority\n","if main_project_dir not in sys.path:\n","    sys.path.insert(0, main_project_dir)\n","\n","importlib.reload(main)\n","print(main.__file__)\n","\n","main.main(project_id, dataset_historical, table_historical, dataset_month, table_id_8h_current, table_id_8h_prediction_current, dataset_prediction)"],"metadata":{"id":"wSve1TsK54CP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81468a25-3311-4cdb-dc75-168664f0a176"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/elt_pipeline_weather_forecast/weather_pipeline/main.py\n",">>> main() is running.\n","Project ID: elt-siegburg-weather-forecast\n","Dataset Historical: elt_weather_dataset_historical_siegburg_2017_2024\n","Table Historical: elt_weather_table_historical_siegburg_2017\n","Dataset Month: elt_weather_dataset_siegburg_october_2025\n","Table Current: elt_weather_8h_table_20251103_1010\n",">>> Starting main API fetch\n","Fetching weather data for 2017...\n","  ‚Üí Loaded 8760 hourly records for 2017\n","Fetching weather data for 2018...\n","  ‚Üí Loaded 8760 hourly records for 2018\n","Fetching weather data for 2019...\n"]}]},{"cell_type":"markdown","source":["# Future Dockerize the Project\n","\n","For future dockerization base Dockerfile (comment out):"],"metadata":{"id":"pu_c6797zh23"}},{"cell_type":"code","source":["# dockerfile_code = \"\"\"\n","# FROM python:3.10-slim\n","\n","# WORKDIR /app\n","\n","# COPY . .\n","\n","# RUN pip install --no-cache-dir -r requirements.txt\n","\n","# CMD [\"python\", \"main.py\"]\n","# \"\"\"\n","\n","# with open(f\"{project_dir}/Dockerfile\", \"w\") as f:\n","#     f.write(dockerfile_code)\n"],"metadata":{"id":"uFbLz3t9zhgB"},"execution_count":null,"outputs":[]}]}